---
title: "Predicting Housing Prices - Data Analysis Project"
author: "Aaron Blythe, ablythe; Josh Janda: joshlj2; Jeanette Pettibone, jgp4"
date: "7/21/2019"
output:
  html_document: 
    toc: yes
  pdf_document: default
urlcolor: cyan
---

Installation note: You may need to install Cairo on your operating system to run this notebook. See README for details.
```{r}
if(!require(Cairo)) install.packages("Cairo", repos = "http://cran.us.r-project.org")
```

# Introduction

The purpose of this project is to predict the price of houses in California in 1990 based on a number of possible location-based predictors, including latitude, longitude, and information about houses within a particular block.

While this project focuses on prediction we are fully aware and want you the reader to also be aware that housing prices increased incredibly after this time period, then the bubble burst for a while and housing prices increased again. This model should not be used to predict the actual future. This is a purely academic endeavor to explore statistical prediction.

The goal of the project is to create the model that can best predict home prices in California given reasonable test/train splits in the data.

## Dataset

We're using the California Housing Prices dataset from the following Kaggle site: https://www.kaggle.com/camnugent/california-housing-prices.  This data pertains to the houses found in a given California district and some summary stats about them based on the 1990 census data.  

We loaded `housing.csv` into R.

```{r}
library(readr)
library(knitr)
library(caret)

housing_data = read_csv("housing.csv")
housing_data$median_house_value[1:100]
```

The dataset contains 20640 observations and 10 attributes (9 predictors and 1 response).  Below is a list of the variables with descriptions taken from the original Kaggle site given above.  

- longitude: A measure of how far west a house is; a higher value is farther west
- latitude: A measure of how far north a house is; a higher value is farther north
- housingMedianAge: Median age of a house within a block; a lower number is a newer building
- totalRooms: Total number of rooms within a block
- totalBedrooms: Total number of bedrooms within a block
- population: Total number of people residing within a block
- households: Total number of households, a group of people residing within a home unit, for a block
- medianIncome: Median income for households within a block of houses (measured in tens of thousands of US Dollars)
- oceanProximity: Location of the house w.r.t ocean/sea
- medianHouseValue: Median house value for households within a block (measured in US Dollars)

This dataset meets all of the stated criteria for the project including:

* A minimum 200 observations
* A numeric response variable - `median_house_value`
* At least one categorical predictor- `oceanProximity`
* At least two numeric predictors - the remaining attributes 

Let's look at a summary of each column.

```{r}
summary(housing_data)#gives us a summary of each column. Note that total bedrooms has 207 NA's. We will need to impute these values
```

## Data Cleaning

Initial exploration of the data showed us that there were a few steps we needed to take to make the data more useable.  Firstly, we changed the categorical variable `oceanProximity` from text-based to a factor variable.  

```{r}
housing_data$ocean_proximity = as.factor(housing_data$ocean_proximity)
ocean_proximity = housing_data$ocean_proximity
```

We see that the factor variable `oceanProximity` has the following $`r length(levels(ocean_proximity))`$ levels: $`r levels(ocean_proximity)`$.

The other thing to consider is missing data.

```{r}
sum(is.na(housing_data))
total_bedrooms = housing_data$total_bedrooms
sum(is.na(total_bedrooms))
```

There are $`r sum(is.na(total_bedrooms))`$ observations with missing data for `total_bedrooms`.  We'll need to figure out how to handle this missing data.  However, looking at the relationship between `total_bedrooms` and `total_rooms`, it looks possible that this is collinearity and we won't gain any information by using `total_bedrooms` variable in our model.  Further testing is required before we can make this decision.

```{r}
plot(housing_data$total_bedrooms ~ housing_data$total_rooms, col="dodgerblue")
```

Other possible things we could do is to fill in the missing `total_bedrooms` data with the median value of `total_bedrooms` grouped by `total_rooms`, since there is a relationship. 

```{r, message = FALSE, warning = FALSE}
library(tidyverse)
housing_data %>% 
  group_by(total_rooms) %>% 
  summarize(median.total_bedrooms = median(total_bedrooms, na.rm = TRUE))
```

Looking at the structure of the dataset after this clean up, we see that besides the one factor variable `ocean_proximity`, we are left with nine numeric variables, three of which are continuous (`longitude`, `latitude`, and `median_income`) and six of which are discrete (`housing_median_age`, `total_rooms`, `total_bedrooms`, `population`, `households`, and `median_house_value`).

```{r}
str(housing_data)
```

Let's look a bit more closely at the distribution of the numeric variables.

```{r, fig.height=10, fig.width=14}
par(mfrow = c(3, 3))
hist(housing_data$longitude, breaks = 20, main = "longitude", border="darkorange", col="dodgerblue")
hist(housing_data$latitude, breaks = 20, main = "latitude", border="darkorange", col="dodgerblue")
hist(housing_data$housing_median_age, breaks = 20, main = "housing_median_age", border="darkorange", col="dodgerblue")
hist(housing_data$total_rooms, breaks = 20, main = "total_rooms", border="darkorange", col="dodgerblue")
hist(housing_data$total_bedrooms, breaks = 20, main = "total_bedrooms", border="darkorange", col="dodgerblue")
hist(housing_data$population, breaks = 20, main = "population", border="darkorange", col="dodgerblue")
hist(housing_data$households, breaks = 20, main = "households", border="darkorange", col="dodgerblue")
hist(housing_data$median_income, breaks = 20, main = "median_income", border="darkorange", col="dodgerblue")
hist(housing_data$median_house_value, breaks = 20, main = "median_house_value", border="darkorange", col="dodgerblue")
```

And let's look at the relationships between all the possible variables.

```{r cache=TRUE}
pairs(housing_data, col = "dodgerblue")
```

In addition to the already mentioned linear relationship between total rooms and total bedrooms, we will also need to look into potential coliearity of households and total bedrooms (and potentially total rooms).

# Methods

```{r cache=TRUE}
library(ggplot2)
#we want to look at shape of distribution to get a good idea of what to impute
ggplot(housing_data, aes(x = total_bedrooms)) +
  geom_histogram(bins = 40) +
  xlab("Total Bedrooms") +
  ylab("Density") +
  ggtitle("Histogram of Total Bedrooms (noncontinuous variable)")
#using mean for now
```



```{r}
library(mice)

housing_data_temp = mice(data = housing_data, m = 5, method = "mean", seed = 420)
housing_data_full  = complete(housing_data_temp, 1)
housing_data_full$ocean_proximity = as.factor(housing_data_full$ocean_proximity)
```


```{r}
housing_data_nc = housing_data_full[, -10]#remove text variable for now

corrmatrix = cor(housing_data_nc)

kable(t(corrmatrix))

highcorr = findCorrelation(corrmatrix, cutoff = .60)#this will give you highly correlated variables
```

```{r}
library(scales)
library(RColorBrewer)
library(plotly)

plot_map = ggplot(housing_data_full, 
                  aes(x = longitude, y = latitude, color = median_house_value, hma = housing_median_age,
                      tr = total_rooms, tb = total_bedrooms, hh = households, mi = median_income)) +
              geom_point(aes(size = population), alpha = 0.4) +
              xlab("Longitude") +
              ylab("Latitude") +
              ggtitle("Data Map - Longtitude vs Latitude and Associated Variables") +
              theme(plot.title = element_text(hjust = 0.5)) +
              scale_color_distiller(palette = "Paired", labels = comma) +
              labs(color = "Median House Value (in $USD)", size = "Population")
plot_map_tt = ggplotly(plot_map)

plot_map_tt
```

```{r}
temp_housing_data = housing_data_full[housing_data_full$ocean_proximity != "ISLAND", ] #possibly consider removing #ISLAND promiximity homes. There are 5 in the dataset out of 20k observations.

start_mod = lm(median_house_value ~ (.)^2, data = temp_housing_data)
 
n = length(resid(start_mod))
back_bic_mod = step(start_mod, direction = "backward", k = log(n), trace = 0)
summary(back_bic_mod)
```



```{r echo=TRUE}
#lets use Weighted Least Squares on this model to cover potential heteroskedasticity.

back_bic_mod_fitted = fitted(back_bic_mod)
back_bic_mod_resid = resid(back_bic_mod)

temp_wls_mod = lm(log(back_bic_mod_resid^2) ~ back_bic_mod_fitted + back_bic_mod_fitted^2)
ghat = fitted(temp_wls_mod)
hhat = exp(ghat)

WLS_back_bic_mod = update(back_bic_mod, weights = 1 / hhat)# to do: #figure out how to get call

plot(
      back_bic_mod$fitted.values,
      back_bic_mod$residuals
)
plot(
      WLS_back_bic_mod$fitted.values,
      WLS_back_bic_mod$residuals
)
```
