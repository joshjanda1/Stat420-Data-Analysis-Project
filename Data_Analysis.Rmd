---
title: "Data Analysis"
output: html_document
---

```{r}
library(readr)
library(knitr)
library(caret)

housing_data = read_csv("housing.csv")#first line of housing 
housing_data$median_house_value[1:100]

```
```{r}
summary(housing_data)#gives us a summary of each column. Note that total bedrooms has 207 NA's. We will need to impute these values
```
```{r}
library(ggplot2)
#we want to look at shape of distribution to get a good idea of what to impute
ggplot(housing_data, aes(x = total_bedrooms)) +
  geom_histogram(bins = 40) +
  xlab("Total Bedrooms") +
  ylab("Density") +
  ggtitle("Histogram of Total Bedrooms (noncontinuous variable)")
#using mean for now
```
```{r}
library(mice)

housing_data_temp = mice(data = housing_data, m = 5, method = "mean", seed = 420)
housing_data_full  = complete(housing_data_temp, 1)
housing_data_full$ocean_proximity = as.factor(housing_data_full$ocean_proximity)
```


```{r}
housing_data_nc = housing_data_full[, -10]#remove text variable for now

corrmatrix = cor(housing_data_nc)

kable(t(corrmatrix))

highcorr = findCorrelation(corrmatrix, cutoff = .60)#this will give you highly correlated variables
```

```{r}
library(scales)
library(RColorBrewer)
library(plotly)

plot_map = ggplot(housing_data_full, 
                  aes(x = longitude, y = latitude, color = median_house_value, hma = housing_median_age,
                      tr = total_rooms, tb = total_bedrooms, hh = households, mi = median_income)) +
              geom_point(aes(size = population), alpha = 0.4) +
              xlab("Longitude") +
              ylab("Latitude") +
              ggtitle("Data Map - Longtitude vs Latitude and Associated Variables") +
              theme(plot.title = element_text(hjust = 0.5)) +
              scale_color_distiller(palette = "Paired", labels = comma) +
              labs(color = "Median House Value (in $USD)", size = "Population")
plot_map_tt = ggplotly(plot_map)

#plot_map_tt
```

```{r}
temp_housing_data = housing_data_full[housing_data_full$ocean_proximity != "ISLAND", ] #possibly consider removing #ISLAND promiximity homes. There are 5 in the dataset out of 20k observations.
set.seed(420)
train_index = createDataPartition(temp_housing_data$ocean_proximity, p = .70, list = FALSE)

housing_train = temp_housing_data[train_index,]
housing_test = temp_housing_data[-train_index,]
```

```{r}
start_mod = lm(median_house_value ~ (.)^2, data = housing_train)
 
n = length(resid(start_mod))
back_bic_mod = step(start_mod, direction = "backward", k = log(n), trace = FALSE)
summary(back_bic_mod)
```



```{r echo=TRUE}
#lets use Weighted Least Squares on this model to cover potential heteroskedasticity.

back_bic_mod_fitted = fitted(back_bic_mod)
back_bic_mod_resid = resid(back_bic_mod)

temp_wls_mod = lm(log(back_bic_mod_resid^2) ~ back_bic_mod_fitted + back_bic_mod_fitted^2)
ghat = fitted(temp_wls_mod)
hhat = exp(ghat)

WLS_back_bic_mod = update(back_bic_mod, weights = 1 / hhat)# to do: #figure out how to get call

plot(
      back_bic_mod$fitted.values,
      back_bic_mod$residuals
)
plot(
      WLS_back_bic_mod$fitted.values,
      WLS_back_bic_mod$residuals
)
```
```{r}
rmse = function(predicted, actual) {
  sqrt(sum((predicted - actual)^2) / length(actual))
}
```
```{r}
rmse_train_norm = rmse(back_bic_mod$fitted.values, housing_train$median_house_value)
rmse_train_wls = rmse(WLS_back_bic_mod$fitted.values, housing_train$median_house_value)

predicted_norm = predict(back_bic_mod, housing_test)
predicted_wls = predict(WLS_back_bic_mod, housing_test)

rmse_test_norm = rmse(predicted_norm, housing_test$median_house_value)
rmse_test_wls = rmse(predicted_wls, housing_test$median_house_value)


rmse_results = data.frame(
                          "Normal Model" = c(rmse_train_norm, rmse_test_norm),
                          "WLS Model" = c(rmse_train_wls, rmse_test_wls)
                          )

kable(t(rmse_results), col.names = c("Train RMSE", "Test RMSE"))
##We can see here that WLS is garbage. Throw it away and pretend I never included it

```

